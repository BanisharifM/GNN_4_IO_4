Running tabgnn model...
Epoch 00019: reducing learning rate of group 0 to 5.0000e-04.
Epoch 00037: reducing learning rate of group 0 to 2.5000e-04.
tabgnn model completed.
Running lightgbm model...
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000592 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11467
[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 45
[LightGBM] [Info] Start training from score 0.038149
lightgbm model completed.
Running catboost model...
catboost model completed.
Running xgboost model...
xgboost model completed.
Running mlp model...
mlp model completed.
Running tabnet model...
epoch 0  | loss: 10.98163|  0:00:00s
epoch 1  | loss: 4.44806 |  0:00:00s
epoch 2  | loss: 1.6966  |  0:00:00s
epoch 3  | loss: 1.02974 |  0:00:00s
epoch 4  | loss: 0.84413 |  0:00:01s
epoch 5  | loss: 0.59838 |  0:00:01s
epoch 6  | loss: 0.48256 |  0:00:01s
epoch 7  | loss: 0.37364 |  0:00:01s
epoch 8  | loss: 0.30514 |  0:00:01s
epoch 9  | loss: 0.26719 |  0:00:01s
epoch 10 | loss: 0.22013 |  0:00:01s
epoch 11 | loss: 0.19416 |  0:00:01s
epoch 12 | loss: 0.17378 |  0:00:01s
epoch 13 | loss: 0.15326 |  0:00:02s
epoch 14 | loss: 0.16288 |  0:00:02s
epoch 15 | loss: 0.12729 |  0:00:02s
epoch 16 | loss: 0.11465 |  0:00:02s
epoch 17 | loss: 0.10808 |  0:00:02s
epoch 18 | loss: 0.09273 |  0:00:02s
epoch 19 | loss: 0.08563 |  0:00:02s
epoch 20 | loss: 0.07887 |  0:00:02s
epoch 21 | loss: 0.06787 |  0:00:03s
epoch 22 | loss: 0.0577  |  0:00:03s
epoch 23 | loss: 0.05771 |  0:00:03s
epoch 24 | loss: 0.0513  |  0:00:03s
epoch 25 | loss: 0.04593 |  0:00:03s
epoch 26 | loss: 0.04346 |  0:00:03s
epoch 27 | loss: 0.04144 |  0:00:03s
epoch 28 | loss: 0.04176 |  0:00:03s
epoch 29 | loss: 0.03911 |  0:00:03s
epoch 30 | loss: 0.031   |  0:00:03s
epoch 31 | loss: 0.02872 |  0:00:04s
epoch 32 | loss: 0.02628 |  0:00:04s
epoch 33 | loss: 0.02899 |  0:00:04s
epoch 34 | loss: 0.02612 |  0:00:04s
epoch 35 | loss: 0.02297 |  0:00:04s
epoch 36 | loss: 0.02247 |  0:00:04s
epoch 37 | loss: 0.02074 |  0:00:04s
epoch 38 | loss: 0.02055 |  0:00:04s
epoch 39 | loss: 0.02169 |  0:00:04s
epoch 40 | loss: 0.01941 |  0:00:04s
epoch 41 | loss: 0.02071 |  0:00:05s
epoch 42 | loss: 0.01888 |  0:00:05s
epoch 43 | loss: 0.01777 |  0:00:05s
epoch 44 | loss: 0.01744 |  0:00:05s
epoch 45 | loss: 0.01752 |  0:00:05s
epoch 46 | loss: 0.01825 |  0:00:05s
epoch 47 | loss: 0.01646 |  0:00:05s
epoch 48 | loss: 0.01794 |  0:00:05s
epoch 49 | loss: 0.01506 |  0:00:05s
epoch 50 | loss: 0.01697 |  0:00:06s
epoch 51 | loss: 0.01767 |  0:00:06s
epoch 52 | loss: 0.01594 |  0:00:06s
epoch 53 | loss: 0.01575 |  0:00:06s
epoch 54 | loss: 0.01611 |  0:00:06s
epoch 55 | loss: 0.01434 |  0:00:06s
epoch 56 | loss: 0.01332 |  0:00:06s
epoch 57 | loss: 0.01248 |  0:00:06s
epoch 58 | loss: 0.01126 |  0:00:06s
epoch 59 | loss: 0.01252 |  0:00:06s
epoch 60 | loss: 0.01155 |  0:00:07s
epoch 61 | loss: 0.01172 |  0:00:07s
epoch 62 | loss: 0.01013 |  0:00:07s
epoch 63 | loss: 0.0105  |  0:00:07s
epoch 64 | loss: 0.01122 |  0:00:07s
epoch 65 | loss: 0.01106 |  0:00:07s
epoch 66 | loss: 0.01125 |  0:00:07s
epoch 67 | loss: 0.01057 |  0:00:07s
epoch 68 | loss: 0.01038 |  0:00:07s
epoch 69 | loss: 0.01124 |  0:00:08s
epoch 70 | loss: 0.00903 |  0:00:08s
epoch 71 | loss: 0.01042 |  0:00:08s
epoch 72 | loss: 0.00968 |  0:00:08s
epoch 73 | loss: 0.00861 |  0:00:08s
epoch 74 | loss: 0.00841 |  0:00:08s
epoch 75 | loss: 0.00784 |  0:00:08s
epoch 76 | loss: 0.00862 |  0:00:08s
epoch 77 | loss: 0.00808 |  0:00:08s
epoch 78 | loss: 0.00795 |  0:00:08s
epoch 79 | loss: 0.00905 |  0:00:09s
epoch 80 | loss: 0.00876 |  0:00:09s
epoch 81 | loss: 0.00866 |  0:00:09s
epoch 82 | loss: 0.00826 |  0:00:09s
epoch 83 | loss: 0.00737 |  0:00:09s
epoch 84 | loss: 0.00816 |  0:00:09s
epoch 85 | loss: 0.00758 |  0:00:09s
epoch 86 | loss: 0.00823 |  0:00:09s
epoch 87 | loss: 0.00711 |  0:00:09s
epoch 88 | loss: 0.00791 |  0:00:10s
epoch 89 | loss: 0.00751 |  0:00:10s
epoch 90 | loss: 0.00647 |  0:00:10s
epoch 91 | loss: 0.00784 |  0:00:10s
epoch 92 | loss: 0.00798 |  0:00:10s
epoch 93 | loss: 0.00814 |  0:00:10s
epoch 94 | loss: 0.00779 |  0:00:10s
epoch 95 | loss: 0.00774 |  0:00:10s
epoch 96 | loss: 0.00754 |  0:00:10s
epoch 97 | loss: 0.00721 |  0:00:10s
epoch 98 | loss: 0.00652 |  0:00:11s
epoch 99 | loss: 0.00753 |  0:00:11s
tabnet model completed.
Running combined model...
Epoch 00019: reducing learning rate of group 0 to 5.0000e-04.
Epoch 00037: reducing learning rate of group 0 to 2.5000e-04.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068869 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 27787
[LightGBM] [Info] Number of data points in the train set: 10000, number of used features: 109
[LightGBM] [Info] Start training from score 0.037983
combined model completed.
All jobs completed at Mon May 26 17:51:01 CDT 2025
